import cloudscraper # å¼•å…¥ç»•è¿‡ 403 çš„åº“
import smtplib
from email.mime.text import MIMEText
from email.header import Header
import os
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from email.utils import parsedate_to_datetime
import time
import random

# 1. è·å–é…ç½®
TARGET_USER = os.environ.get("TARGET_USER")
MAIL_USER = os.environ.get("MAIL_USER")
MAIL_PASS = os.environ.get("MAIL_PASS")
RECEIVER = os.environ.get("RECEIVER")

# === èŠ‚ç‚¹åˆ—è¡¨ ===
# æ··åˆäº† Nitter å’Œ RSSHub çš„èŠ‚ç‚¹ï¼Œå¢åŠ æˆåŠŸç‡
NODES = [
    f"https://nitter.cz/{TARGET_USER}/rss",
    f"https://nitter.poast.org/{TARGET_USER}/rss",
    f"https://nitter.privacydev.net/{TARGET_USER}/rss",
    f"https://nitter.woodland.cafe/{TARGET_USER}/rss",
    f"https://nitter.x86-64-unknown-linux-gnu.zip/{TARGET_USER}/rss",
]

def send_email(title, link, pub_date):
    mail_host = "smtp.qq.com"
    content = f"æ—¶é—´: {pub_date}\n\nå†…å®¹: {title}\n\né“¾æ¥: {link}"
    message = MIMEText(content, 'plain', 'utf-8')
    message['From'] = Header("TwitterMonitor", 'utf-8')
    message['To'] = Header("User", 'utf-8')
    message['Subject'] = Header(f"ã€æ–°æ¨æ–‡ã€‘{TARGET_USER} æ›´æ–°äº†", 'utf-8')

    try:
        smtpObj = smtplib.SMTP_SSL(mail_host, 465)
        smtpObj.login(MAIL_USER, MAIL_PASS)
        smtpObj.sendmail(MAIL_USER, RECEIVER, message.as_string())
        print(f"âœ… é‚®ä»¶å·²å‘é€: {title}")
    except Exception as e:
        print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")

def get_rss_content():
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨çš„ scraper
    scraper = cloudscraper.create_scraper(
        browser={
            'browser': 'chrome',
            'platform': 'windows',
            'desktop': True
        }
    )
    
    # éšæœºæ‰“ä¹±èŠ‚ç‚¹é¡ºåºï¼Œé¿å…æ€»æ˜¯æ­»ç£•ç¬¬ä¸€ä¸ª
    random.shuffle(NODES)

    for url in NODES:
        print(f"ğŸ”„ æ­£åœ¨å°è¯•: {url} ...")
        try:
            # ä½¿ç”¨ scraper.get è€Œä¸æ˜¯ requests.get
            resp = scraper.get(url, timeout=15)
            
            if resp.status_code == 200:
                # å†æ¬¡ç¡®è®¤å†…å®¹æ˜¯å¦åŒ…å« RSS æ ‡è®°
                if b"<rss" in resp.content or b"<feed" in resp.content:
                    print(f"âœ… æˆåŠŸè¿æ¥ï¼")
                    return resp.content
                else:
                    print(f"âš ï¸ çŠ¶æ€200ä½†å†…å®¹ä¸å¯¹ (å¯èƒ½æ˜¯å‡ç½‘é¡µ)ï¼Œè·³è¿‡ã€‚")
            else:
                print(f"âŒ çŠ¶æ€ç : {resp.status_code}")
                
        except Exception as e:
            # åªæ‰“å°ç®€çŸ­é”™è¯¯ï¼Œä¸åˆ·å±
            error_msg = str(e).split('(')[0]
            print(f"âŒ è¿æ¥å‡ºé”™: {error_msg}")
            
    return None

def check_twitter():
    content = get_rss_content()
    if not content:
        print("ğŸš¨ æ‰€æœ‰èŠ‚ç‚¹éƒ½é˜µäº¡äº†ã€‚GitHub IP å¯èƒ½è¢«æš‚æ—¶å°é”ã€‚")
        return

    try:
        root = ET.fromstring(content)
        items = root.findall(".//item")
        
        if not items:
            print("ğŸ“­ æœªæ‰¾åˆ°æ¨æ–‡")
            return

        latest_item = items[0]
        title = latest_item.find("title").text
        link = latest_item.find("link").text
        pub_date_str = latest_item.find("pubDate").text
        
        tweet_time = parsedate_to_datetime(pub_date_str)
        now = datetime.now(tweet_time.tzinfo)
        
        # 40åˆ†é’Ÿåˆ¤å®š
        if (now - tweet_time) < timedelta(minutes=40):
            print("ğŸ”” å‘ç°æ–°æ¨æ–‡ï¼Œå‡†å¤‡å‘é€...")
            send_email(title, link, pub_date_str)
        else:
            print(f"ğŸ’¤ æœ€æ–°æ¨æ–‡æ˜¯æ—§çš„ ({pub_date_str})ï¼Œä¸å‘é€ã€‚")
            
    except Exception as e:
        print(f"ğŸ’¥ è§£æå‡ºé”™: {e}")

if __name__ == "__main__":
    check_twitter()
